{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bb7048f",
   "metadata": {},
   "source": [
    "# Project heading and title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c573142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd \n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a901a65d",
   "metadata": {},
   "source": [
    "# Special instructions about script\n",
    "\n",
    "## Dont run script unless you are downloading the data again, script will download data into \"/data/downloaded\" section\n",
    "\n",
    "## The downloaded data is also located in a folder if you dont want to run the script, located in \"/data/original\"\n",
    "\n",
    "## Read more into this in the readme, section \"API request script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de35a653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the script to download the json files\n",
    "# remove this to activate url: url = \"https://api.nasa.gov/neo/rest/v1/feed\"\n",
    "# remove this and use your API key here: api_key = \"*insert api key here*\"\n",
    "\n",
    "# Specify the start and end dates for the first week and the folder path\n",
    "start_date = \"2022-01-01\"\n",
    "end_date = \"2022-01-07\"\n",
    "folder_path = \"data/downloaded\"\n",
    "\n",
    "# Our api only allows 7 days at a time, so let's iterate over the start and end dates for 7 days at a time (see below)\n",
    "while start_date <= \"2022-12-31\":\n",
    "\n",
    "    parameters = {\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"api_key\": api_key\n",
    "    }\n",
    "\n",
    "    # Here is our actual API request\n",
    "    response = requests.get(url, params=parameters)\n",
    "\n",
    "    # Here we will save the file with a custom filename for the week it contains\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        asteroids = data[\"near_earth_objects\"]\n",
    "        file_name = f\"week_{start_date}.json\"\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Save the json file and output a confirmation that the file was downloaded successfully\n",
    "        with open(file_path, \"w\") as file:\n",
    "            json.dump(asteroids, file)\n",
    "            print(f\"JSON data for {start_date} to {end_date} saved successfully.\")\n",
    "            #If this is successful, you will see 53 success responses, may take 5-10 minutes\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {start_date} to {end_date} from the API.\")\n",
    "  \n",
    "        \n",
    "    # Here we can use strptime, strftime from the datetime library to convert the start/end date to datetime elements\n",
    "    # Then we can add 7 days to that datetime element and convert the value back to a string to be used in the request\n",
    "    start_date = (datetime.datetime.strptime(start_date, \"%Y-%m-%d\") + datetime.timedelta(days=7)).strftime(\"%Y-%m-%d\")\n",
    "    end_date = (datetime.datetime.strptime(end_date, \"%Y-%m-%d\") + datetime.timedelta(days=7)).strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414708c9",
   "metadata": {},
   "source": [
    "# Section 2\n",
    "\n",
    "## Here we will be scraping our json files for only the specified data we want and putting that into a dataframe\n",
    "\n",
    "### include in readme about changing the glob file path if you are choosing the downloadedvsincluded data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea39b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "asteroid_data = []\n",
    "\n",
    "# Let's use glob to iterate over the file names of our json files, and then load the json files into the data variable\n",
    "for file_name in glob.glob('data/original/*.json'):\n",
    "    with open(file_name) as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "        # This loop allows us to iterate over each asteroid and take out particular data from each asteroid\n",
    "        for date, asteroids in data.items():\n",
    "            for asteroid in asteroids:\n",
    "                asteroid_id = asteroid['id']\n",
    "                asteroid_name = asteroid['name']\n",
    "                asteroid_diameter_min = asteroid['estimated_diameter']['feet']['estimated_diameter_min']\n",
    "                asteroid_diameter_max = asteroid['estimated_diameter']['feet']['estimated_diameter_max']\n",
    "                asteroid_potentially_hazardous = asteroid['is_potentially_hazardous_asteroid']\n",
    "                \n",
    "                # Since we have a nested list in our json, we have to create a nested loop for this data\n",
    "                for approach in asteroid['close_approach_data']:\n",
    "                    \n",
    "                    asteroid_relative_velocity = approach['relative_velocity']['miles_per_hour']\n",
    "                    asteroid_miss_distance = approach['miss_distance']['miles']\n",
    "                    asteroid_date = approach['close_approach_date']\n",
    "                    \n",
    "                    # Here we append our dictionary and create our new column names\n",
    "                    asteroid_data.append({\n",
    "                        'ID': asteroid_id,\n",
    "                        'Name': asteroid_name,\n",
    "                        'Diameter_Min_Feet': asteroid_diameter_min,\n",
    "                        'Diameter_Max_Feet': asteroid_diameter_max,\n",
    "                        'Relative_Velocity_MPH': asteroid_relative_velocity,\n",
    "                        'Miss_Distance_Miles': asteroid_miss_distance,\n",
    "                        'Is_Potentially_Hazardous': asteroid_potentially_hazardous,\n",
    "                        'Date': asteroid_date\n",
    "                    })\n",
    "            \n",
    "df = pd.DataFrame(asteroid_data)\n",
    "\n",
    "# Let's add a column to give us the average estimated diameter\n",
    "df['Average_Diameter_Feet'] = (df['Diameter_Min_Feet'] + df['Diameter_Max_Feet']) / 2\n",
    "\n",
    "# Next let's convert our data from year-month-day to month-day-year\n",
    "# We can do this by converting the date to date-time type and then changing the format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Date'] = df['Date'].dt.strftime('%m-%d-%Y')\n",
    "\n",
    "# Now let's rearrange the columns to make it easier to read\n",
    "column_order = ['Date', 'Name', 'Diameter_Min_Feet', 'Diameter_Max_Feet', 'Average_Diameter_Feet', 'Relative_Velocity_MPH', 'Miss_Distance_Miles', 'Is_Potentially_Hazardous', 'ID']\n",
    "df = df[column_order]\n",
    "\n",
    "# Finally, lets sort our dataframe based on the date\n",
    "df.sort_values('Date', inplace=True)\n",
    "\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "#df.to_excel('data/output.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835ac5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
