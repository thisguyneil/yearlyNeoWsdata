{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bb7048f",
   "metadata": {},
   "source": [
    "# Yearly NeoWs data and the effect on tides\n",
    "\n",
    "## This project will examine data from the NASA Near Earth Object Web Service and the Permanent Service for Mean Sea Level to see if near earth asteroids in 2020 had an effect on tide levels.\n",
    "\n",
    "### More information about the project including how to get the project working on your computer is located in the readme in the directory of this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd \n",
    "import glob\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a901a65d",
   "metadata": {},
   "source": [
    "# 1. Getting our asteroid data\n",
    "\n",
    "## This section is optional and will show the method I used to download the NeoWs data for 2020 from NASA using their API. The process can be long so if you are not wanting to sign up for an API key from the NASA website and download the data manually, the needed data is included in the data/original folder in the directory. I have commented out key sections of this script to prevent accidently running it as it can take upwards of 5 minutes to download all files. If you are wanting to run this script to test it out, please look into the readme under the section titled \"1. Getting our asteroid data.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de35a653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the script to download the json files\n",
    "url = \"https://api.nasa.gov/neo/rest/v1/feed\"\n",
    "# Remove this to input API key: api_key = \"*insert API key here*\"\n",
    "\n",
    "# Specify the start and end dates for the first week and the folder path\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2020-01-07\"\n",
    "folder_path = \"data/downloaded\"\n",
    "\n",
    "# Our api only allows 7 days at a time, so let's iterate over the start and end dates for 7 days at a time (see below)\n",
    "while start_date <= \"2020-12-31\":\n",
    "\n",
    "    parameters = {\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"api_key\": api_key\n",
    "    }\n",
    "\n",
    "    # Here is our actual API request\n",
    "    response = requests.get(url, params=parameters)\n",
    "\n",
    "    # Here we will save the file with a custom filename for the week it contains\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        asteroids = data[\"near_earth_objects\"]\n",
    "        file_name = f\"week_{start_date}.json\"\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Save the json file and output a confirmation that the file was downloaded successfully\n",
    "        with open(file_path, \"w\") as file:\n",
    "            json.dump(asteroids, file)\n",
    "            print(f\"JSON data for {start_date} to {end_date} saved successfully.\")\n",
    "            #If this is successful, you will see 53 success responses, may take 5-10 minutes\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {start_date} to {end_date} from the API.\")\n",
    "  \n",
    "        \n",
    "    # Here we can use strptime, strftime from the datetime library to convert the start/end date to datetime elements\n",
    "    # Then we can add 7 days to that datetime element and convert the value back to a string to be used in the request\n",
    "    start_date = (datetime.datetime.strptime(start_date, \"%Y-%m-%d\") + datetime.timedelta(days=7)).strftime(\"%Y-%m-%d\")\n",
    "    end_date = (datetime.datetime.strptime(end_date, \"%Y-%m-%d\") + datetime.timedelta(days=7)).strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414708c9",
   "metadata": {},
   "source": [
    "# 2. Cleaning our NeoWs data\n",
    "\n",
    "## Here we will be scraping our json files for only the specified data we want and putting that into a dataframe\n",
    "\n",
    "## If you are downloading the data yourself to test out the code, please read the readme for this section under \"2. Cleaning our NeoWs data\" for the changes you need to make, otherwise you can leave this section as-is if you are using the included \"original\" data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea39b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "asteroid_data = []\n",
    "\n",
    "# Let's use glob to iterate over the file names of our json files, and then load the json files into the data variable\n",
    "for file_name in glob.glob('data/original/*.json'):\n",
    "    with open(file_name) as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "        # This loop allows us to iterate over each asteroid and take out particular data from each asteroid\n",
    "        for date, asteroids in data.items():\n",
    "            for asteroid in asteroids:\n",
    "                asteroid_id = asteroid['id']\n",
    "                asteroid_name = asteroid['name']\n",
    "                asteroid_diameter_min = asteroid['estimated_diameter']['feet']['estimated_diameter_min']\n",
    "                asteroid_diameter_max = asteroid['estimated_diameter']['feet']['estimated_diameter_max']\n",
    "                asteroid_potentially_hazardous = asteroid['is_potentially_hazardous_asteroid']\n",
    "                \n",
    "                # Since we have a nested list in our json, we have to create a nested loop for this data\n",
    "                for approach in asteroid['close_approach_data']:\n",
    "                    \n",
    "                    asteroid_relative_velocity = approach['relative_velocity']['miles_per_hour']\n",
    "                    asteroid_miss_distance = approach['miss_distance']['miles']\n",
    "                    asteroid_date = approach['close_approach_date']\n",
    "                    \n",
    "                    # Here we append our dictionary and create our new column names\n",
    "                    asteroid_data.append({\n",
    "                        'ID': asteroid_id,\n",
    "                        'Name': asteroid_name,\n",
    "                        'Diameter_Min_Feet': asteroid_diameter_min,\n",
    "                        'Diameter_Max_Feet': asteroid_diameter_max,\n",
    "                        'Relative_Velocity_MPH': asteroid_relative_velocity,\n",
    "                        'Miss_Distance_Miles': asteroid_miss_distance,\n",
    "                        'Is_Potentially_Hazardous': asteroid_potentially_hazardous,\n",
    "                        'Date': asteroid_date\n",
    "                    })\n",
    "            \n",
    "df = pd.DataFrame(asteroid_data)\n",
    "\n",
    "# Let's add a column to give us the average estimated diameter\n",
    "df['Average_Diameter_Feet'] = (df['Diameter_Min_Feet'] + df['Diameter_Max_Feet']) / 2\n",
    "\n",
    "# Next let's convert our data from year-month-day to month-day-year\n",
    "# We can do this by converting the date to date-time type and then changing the format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Date'] = df['Date'].dt.strftime('%m-%d-%Y')\n",
    "\n",
    "# Now let's rearrange the columns to make it easier to read\n",
    "column_order = ['Date', 'Name', 'Diameter_Min_Feet', 'Diameter_Max_Feet', 'Average_Diameter_Feet', 'Relative_Velocity_MPH', 'Miss_Distance_Miles', 'Is_Potentially_Hazardous', 'ID']\n",
    "df = df[column_order]\n",
    "\n",
    "# Finally, lets sort our dataframe based on the date\n",
    "df.sort_values('Date', inplace=True)\n",
    "\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('data/asteroidoutput.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe17f23",
   "metadata": {},
   "source": [
    "# 3. Cleaning our tide data\n",
    "\n",
    "#  We will be comparing tide level data from the PSMSL (Permanent Service for Mean Sea Level) for Shell Beach, Louisiana for 2020.\n",
    "\n",
    "# The data file needed is included in the data folder under \"shellbeachtidedata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ee3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a second pandas data frame and load in our CSV\n",
    "df2 = pd.read_csv('data/shellbeachtidedata.csv', header=9)\n",
    "\n",
    "# Now that the data is loaded, let's scrape the time column and make a date column\n",
    "df2['Date'] = pd.to_datetime(df2['time']).dt.date\n",
    "\n",
    "# Let's convert our date to our preferred format\n",
    "df2['Date'] = pd.to_datetime(df2['Date']).dt.strftime('%m-%d-%Y')\n",
    "\n",
    "# Now let's drop the time column and reorganize our columns\n",
    "del df2['time']\n",
    "column_order2 = ['Date', 'adjusted_height', 'raw_height', 'fitted_tide', 'prn', 'signal', 'azimuth', 'elevation']\n",
    "df2 = df2[column_order2]\n",
    "\n",
    "# Now we can convert our date column to datetime and drop all rows not from 2020\n",
    "df2['Date'] = pd.to_datetime(df2['Date'])\n",
    "df2 = df2[df2['Date'].dt.year == 2020]\n",
    "\n",
    "df2.to_csv('data/tideoutput.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdaecdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be3b5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
